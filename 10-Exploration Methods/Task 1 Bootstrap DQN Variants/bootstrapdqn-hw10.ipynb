{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7343ca",
   "metadata": {
    "papermill": {
     "duration": 0.010213,
     "end_time": "2025-06-13T15:44:07.531188",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.520975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📋 **Student Information**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce1d8a",
   "metadata": {
    "papermill": {
     "duration": 0.008121,
     "end_time": "2025-06-13T15:44:07.548013",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.539892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Complete the required fields below with your personal and W&B account details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca6902e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:44:07.565834Z",
     "iopub.status.busy": "2025-06-13T15:44:07.565613Z",
     "iopub.status.idle": "2025-06-13T15:44:07.572540Z",
     "shell.execute_reply": "2025-06-13T15:44:07.571908Z"
    },
    "papermill": {
     "duration": 0.016995,
     "end_time": "2025-06-13T15:44:07.573614",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.556619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: Ayeen-Poostforoushan-DQN-EXPLORE-HW\n"
     ]
    }
   ],
   "source": [
    "FIRST_NAME = \"Ayeen\" # replace with your first name\n",
    "LAST_NAME = \"Poostforoushan\" # replace with your last name\n",
    "STUDENT_ID = 401105742 # replace with your student id\n",
    "WANDB_ID = \"ayeen-pf-sharif-university-of-technology\" # replace with your wandb username\n",
    "PROJECT_NAME = f\"{FIRST_NAME}-{LAST_NAME}-DQN-EXPLORE-HW\"\n",
    "print(f\"Project name: {PROJECT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bd717c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:44:07.592150Z",
     "iopub.status.busy": "2025-06-13T15:44:07.591937Z",
     "iopub.status.idle": "2025-06-13T15:44:07.595432Z",
     "shell.execute_reply": "2025-06-13T15:44:07.594674Z"
    },
    "papermill": {
     "duration": 0.013593,
     "end_time": "2025-06-13T15:44:07.596525",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.582932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check my results at https://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check my results at https://wandb.ai/{WANDB_ID}/{PROJECT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be98a5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:44:07.615100Z",
     "iopub.status.busy": "2025-06-13T15:44:07.614912Z",
     "iopub.status.idle": "2025-06-13T15:44:07.618116Z",
     "shell.execute_reply": "2025-06-13T15:44:07.617624Z"
    },
    "papermill": {
     "duration": 0.013469,
     "end_time": "2025-06-13T15:44:07.619084",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.605615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set DEBUG to True if you are still implementing the code and debugging\n",
    "# and don't want to make your wandb dashboard messy.\n",
    "# set DEBUG to False if you are almost done with the implementation\n",
    "# and want check performance and compare hyperparameters and models\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd9c4d",
   "metadata": {
    "papermill": {
     "duration": 0.008779,
     "end_time": "2025-06-13T15:44:07.636641",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.627862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📘 Guidelines\n",
    "\n",
    "> ⚠️ **Please read this section carefully before proceeding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b544f",
   "metadata": {
    "papermill": {
     "duration": 0.008415,
     "end_time": "2025-06-13T15:44:07.653762",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.645347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 🔧 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d524eae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:44:07.671770Z",
     "iopub.status.busy": "2025-06-13T15:44:07.671591Z",
     "iopub.status.idle": "2025-06-13T15:46:32.091662Z",
     "shell.execute_reply": "2025-06-13T15:46:32.090454Z"
    },
    "papermill": {
     "duration": 144.43076,
     "end_time": "2025-06-13T15:46:32.093100",
     "exception": false,
     "start_time": "2025-06-13T15:44:07.662340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "build-essential is already the newest version (12.9ubuntu3).\r\n",
      "python3-dev is already the newest version (3.10.6-1~22.04.1).\r\n",
      "python3-dev set to manually installed.\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\r\n",
      "Cloning into 'Homework-10'...\r\n",
      "remote: Enumerating objects: 111, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (111/111), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (67/67), done.\u001B[K\r\n",
      "remote: Total 111 (delta 37), reused 108 (delta 34), pack-reused 0 (from 0)\u001B[K\r\n",
      "Receiving objects: 100% (111/111), 1.14 MiB | 8.97 MiB/s, done.\r\n",
      "Resolving deltas: 100% (37/37), done.\r\n",
      "Collecting swig\r\n",
      "  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\r\n",
      "Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m25.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: swig\r\n",
      "Successfully installed swig-4.3.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing ./Homework-10/BootstrapDQN\r\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "Requirement already satisfied: ale-py<=0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.10.2)\r\n",
      "Collecting dotenv>=0.9.9 (from main==0.1.0)\r\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\r\n",
      "Collecting gymnasium>=1.1.1 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\r\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Collecting ipykernel>=6.29.5 (from main==0.1.0)\r\n",
      "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (5.10.4)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (1.26.4)\r\n",
      "Collecting pip>=25.0.1 (from main==0.1.0)\r\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: swig>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (4.3.1)\r\n",
      "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: wandb>=0.19.9 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.19.9)\r\n",
      "Collecting python-dotenv (from dotenv>=0.9.9->main==0.1.0)\r\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (3.1.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (4.13.2)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (0.0.4)\r\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\r\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m374.4/374.4 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\r\n",
      "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (2.6.1)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.2.2)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.8.0)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.34.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (8.6.3)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.1.7)\r\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.6.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (25.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.0.0)\r\n",
      "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (24.0.1)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (6.4.2)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.1)\r\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (2.21.1)\r\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (4.23.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->main==0.1.0)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->main==0.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (8.1.8)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.1.44)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (4.3.8)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.11.4)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (6.0.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.25.1)\r\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (1.3.5)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.19.9->main==0.1.0) (1.17.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (4.0.12)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (3.0.50)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (2.19.1)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.9.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.24.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.5->main==0.1.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2025.4.26)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->main==0.1.0) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->main==0.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->main==0.1.0) (2024.2.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (5.0.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.13)\r\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m965.4/965.4 kB\u001B[0m \u001B[31m35.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m117.2/117.2 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m68.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m66.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Building wheels for collected packages: main, box2d-py\r\n",
      "  Building wheel for main (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Created wheel for main: filename=main-0.1.0-py3-none-any.whl size=11117 sha256=0b3c20b3fde2ad3e3dae0657b9fb0abf6ba02d9e5bca631b80ad0864bb086c82\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kjrmpdrh/wheels/4f/16/b7/f0afc1a4a4574831edbabf07feb162c98e9e62978951f878e1\r\n",
      "  Building wheel for box2d-py (setup.py) ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379367 sha256=dc167714359696dbb63038a2d2cbfe5e37a16a48263d9de86cd477b801e53e99\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\r\n",
      "Successfully built main box2d-py\r\n",
      "Installing collected packages: box2d-py, python-dotenv, pip, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dotenv, nvidia-cusolver-cu12, ipykernel, gymnasium, main\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 24.1.2\r\n",
      "    Uninstalling pip-24.1.2:\r\n",
      "      Successfully uninstalled pip-24.1.2\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "  Attempting uninstall: ipykernel\r\n",
      "    Found existing installation: ipykernel 6.17.1\r\n",
      "    Uninstalling ipykernel-6.17.1:\r\n",
      "      Successfully uninstalled ipykernel-6.17.1\r\n",
      "  Attempting uninstall: gymnasium\r\n",
      "    Found existing installation: gymnasium 0.29.0\r\n",
      "    Uninstalling gymnasium-0.29.0:\r\n",
      "      Successfully uninstalled gymnasium-0.29.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.1.1 which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.1.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed box2d-py-2.3.5 dotenv-0.9.9 gymnasium-1.1.1 ipykernel-6.29.5 main-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pip-25.1.1 python-dotenv-1.1.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!apt install build-essential python3-dev\n",
    "!git clone https://github.com/DeepRLCourse/Homework-10.git\n",
    "%pip install swig\n",
    "%pip install \"Homework-10/BootstrapDQN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad538e4",
   "metadata": {
    "papermill": {
     "duration": 0.075913,
     "end_time": "2025-06-13T15:46:32.199193",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.123280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 📊 Weights & Biases (W&B) Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e666716",
   "metadata": {
    "papermill": {
     "duration": 0.028922,
     "end_time": "2025-06-13T15:46:32.257274",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.228352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Follow these steps to set up tracking with [Weights & Biases](https://wandb.ai/site/):\n",
    "\n",
    "1. [Create a W&B account](https://wandb.ai/site/).\n",
    "2. Set the `WANDB_ID` variable in the **Student Information** section to your W&B username.\n",
    "3. Create a new project using the name defined in the `PROJECT_NAME` variable. Ensure the project visibility is set to **Public**.\n",
    "4. [Retrieve your W&B API key](https://docs.wandb.ai/support/find_api_key/).\n",
    "5. Set the `WANDB_API_KEY`:\n",
    "   - As a **secret** if you're using **Google Colab** or **Kaggle**\n",
    "   - As an **environment variable** if running locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cfa448",
   "metadata": {
    "papermill": {
     "duration": 0.028407,
     "end_time": "2025-06-13T15:46:32.314945",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.286538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 💻 Platform-Specific Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cee80f",
   "metadata": {
    "papermill": {
     "duration": 0.029445,
     "end_time": "2025-06-13T15:46:32.373719",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.344274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64c7d5",
   "metadata": {
    "papermill": {
     "duration": 0.028882,
     "end_time": "2025-06-13T15:46:32.432077",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.403195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce4db",
   "metadata": {
    "papermill": {
     "duration": 0.028838,
     "end_time": "2025-06-13T15:46:32.489707",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.460869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To configure W&B API key in Kaggle:\n",
    "\n",
    "- Go to: `Add-ons` → `Secrets` → `Add Secret`\n",
    "- **Label:** `WANDB_API_KEY`  \n",
    "- **Value:** `<your_api_key>`\n",
    "\n",
    "> You only need to add the secret — no code changes are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50808fc0",
   "metadata": {
    "papermill": {
     "duration": 0.030056,
     "end_time": "2025-06-13T15:46:32.549119",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.519063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523880c",
   "metadata": {
    "papermill": {
     "duration": 0.029161,
     "end_time": "2025-06-13T15:46:32.608373",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.579212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can set the `WANDB_API_KEY` as an environment variable manually or,\n",
    "\n",
    "store it in a `.env` file:\n",
    "```bash\n",
    "# secrets.env\n",
    "WANDB_API_KEY=your_api_key\n",
    "```\n",
    "and then run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0338a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:32.668790Z",
     "iopub.status.busy": "2025-06-13T15:46:32.668456Z",
     "iopub.status.idle": "2025-06-13T15:46:38.336310Z",
     "shell.execute_reply": "2025-06-13T15:46:38.335034Z"
    },
    "papermill": {
     "duration": 5.700169,
     "end_time": "2025-06-13T15:46:38.338045",
     "exception": false,
     "start_time": "2025-06-13T15:46:32.637876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bootstrapdqn import get_machine\n",
    "if get_machine() == \"Local Machine\":\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv(\".workspace/secrets.env\") # give it the path to your secrets.env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0725e3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:38.407194Z",
     "iopub.status.busy": "2025-06-13T15:46:38.406417Z",
     "iopub.status.idle": "2025-06-13T15:46:38.410840Z",
     "shell.execute_reply": "2025-06-13T15:46:38.410129Z"
    },
    "papermill": {
     "duration": 0.039414,
     "end_time": "2025-06-13T15:46:38.412013",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.372599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# silence only the “To copy construct from a tensor” UserWarning from PyTorch\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach()\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407c375",
   "metadata": {
    "papermill": {
     "duration": 0.032305,
     "end_time": "2025-06-13T15:46:38.477333",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.445028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 📤 Submission Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa63bea",
   "metadata": {
    "papermill": {
     "duration": 0.030553,
     "end_time": "2025-06-13T15:46:38.538686",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.508133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In addition to submitting this notebook on **Quera**, you must:\n",
    "\n",
    "- Have a W&B project matching the name in `PROJECT_NAME`, under the account defined by `WANDB_ID`\n",
    "- Ensure the W&B link displayed in the **Student Information** section is valid\n",
    "- Tag your final experiment run for **each algorithm** with `Final`:\n",
    "  - Go to **Runs** (left sidebar) → **Tags** → Add the tag `Final`\n",
    "  - A total of **four** runs should be tagged as `Final`\n",
    "\n",
    "⚠️ **Important:** The `save_code` option must remain enabled. If a `Final` run does not include saved code, it will **not** be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d9934",
   "metadata": {
    "papermill": {
     "duration": 0.029248,
     "end_time": "2025-06-13T15:46:38.598423",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.569175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 🧮 Grading Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52dcf54",
   "metadata": {
    "papermill": {
     "duration": 0.030144,
     "end_time": "2025-06-13T15:46:38.658323",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.628179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The score for each algorithm is provided in its respective section. This score is then multiplied by the environment score:\n",
    "- `CartPole`: × 0.1\n",
    "    - Minimum requirement: over 200 points across 5 consecutive evaluations\n",
    "- `LunarLander`: × 0.7\n",
    "    - Minimum requirement: over 200 points across 5 consecutive evaluations\n",
    "- `MountainCar`: × 1.0\n",
    "    - Minimum requirement: reach the goal state across 5 consecutive evaluations\n",
    "- `FrozenLake`: × 1.2\n",
    "    - Minimum requirement: reach the goal state across at least 5 evaluations of 15 consecutive evaluations\n",
    "- `SeaQuest`: × 1.5\n",
    "    -  Minimum requirement: over 2000 points across 5 consecutive evaluations\n",
    "\n",
    "Total Score is 100. you can get up to 80 bonus score (180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d07f8",
   "metadata": {
    "papermill": {
     "duration": 0.028813,
     "end_time": "2025-06-13T15:46:38.720795",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.691982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 📝 Implementation Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3927b8",
   "metadata": {
    "papermill": {
     "duration": 0.029421,
     "end_time": "2025-06-13T15:46:38.779289",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.749868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Implement the algorithms as subclasses of `BaseDQNAgent` provided in [`base_agent.py`](https://github.com/DeepRLCourse/Homework-10/blob/main/BootstrapDQN/src/bootstrapdqn/base_agent.py). You may add or override methods/properties as needed.\n",
    "    - The `BaseDQNAgent` code will be automatically downloaded and imported. Ensure you review it carefully before implementing your algorithms.\n",
    "- Code blocks or lines marked with `# DO NOT CHANGE` must remain unaltered in your final submission. You may modify them during development for debugging purposes, but revert them before submitting.\n",
    "- If running locally, real-time W&B logging might face restrictions. Use W&B's offline mode for experiments and sync them later using the `wandb sync` command ([link](https://docs.wandb.ai/support/run_wandb_offline/)).\n",
    "- Prioritize vector operations over loops for better performance. While algorithm descriptions might use loops for clarity, only the main training and rollout loops (implemented in `BaseDQNAgent`) should remain iterative. Failure to vectorize may significantly increase convergence time.\n",
    "- For potentially more stable and faster training, you may consider using *Smooth L1 Loss* instead of Mean Squared Error. (Optional)\n",
    "- Weight initialization significantly impacts performance. Orthogonal initialization is generally recommended in the RL community and might be worth trying.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258ba21",
   "metadata": {
    "papermill": {
     "duration": 0.03735,
     "end_time": "2025-06-13T15:46:38.845889",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.808539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Tips & More"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd62d79",
   "metadata": {
    "papermill": {
     "duration": 0.035003,
     "end_time": "2025-06-13T15:46:38.919443",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.884440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following resource provides general advice for implementing and debugging RL algorithms (not required for this homework, but highly recommended):\n",
    "\n",
    "- [Debugging RL, Without the Agonizing Pain](https://andyljones.com/posts/rl-debugging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3d4a4",
   "metadata": {
    "papermill": {
     "duration": 0.030518,
     "end_time": "2025-06-13T15:46:38.980413",
     "exception": false,
     "start_time": "2025-06-13T15:46:38.949895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧭 Exploration Techniques in DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d974fd",
   "metadata": {
    "papermill": {
     "duration": 0.030944,
     "end_time": "2025-06-13T15:46:39.042350",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.011406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🚀 Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5912a596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:39.107421Z",
     "iopub.status.busy": "2025-06-13T15:46:39.106984Z",
     "iopub.status.idle": "2025-06-13T15:46:39.202667Z",
     "shell.execute_reply": "2025-06-13T15:46:39.202069Z"
    },
    "papermill": {
     "duration": 0.130991,
     "end_time": "2025-06-13T15:46:39.203983",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.072992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS BLOCK\n",
    "from bootstrapdqn import ReplayBuffer, BaseDQNAgent, get_machine, set_wandb_key_form_secrets, envs\n",
    "import torch\n",
    "from torch import nn\n",
    "import wandb\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "from torch.distributions import Bernoulli\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e07bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:39.267142Z",
     "iopub.status.busy": "2025-06-13T15:46:39.266467Z",
     "iopub.status.idle": "2025-06-13T15:46:39.270252Z",
     "shell.execute_reply": "2025-06-13T15:46:39.269544Z"
    },
    "papermill": {
     "duration": 0.036195,
     "end_time": "2025-06-13T15:46:39.271384",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.235189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS BLOCK\n",
    "TA = True if WANDB_ID == \"alireza9\" else False\n",
    "\n",
    "SAVE_CODE = False if TA else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45318b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:39.332789Z",
     "iopub.status.busy": "2025-06-13T15:46:39.332564Z",
     "iopub.status.idle": "2025-06-13T15:46:39.337413Z",
     "shell.execute_reply": "2025-06-13T15:46:39.336658Z"
    },
    "papermill": {
     "duration": 0.03596,
     "end_time": "2025-06-13T15:46:39.338678",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.302718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CartPole': {'env': {'env_config': {}, 'env_name': 'CartPole-v1', 'seed': 43},\n",
      "              'run': {'max_episodes': 1000,\n",
      "                      'max_steps': 50000,\n",
      "                      'max_steps_per_episode': 100000,\n",
      "                      'max_time': 720.0}},\n",
      " 'FrozenLake': {'env': {'env_config': {'p': 0.87, 'size': 14},\n",
      "                        'env_name': 'FrozenLake-v1',\n",
      "                        'seed': 42},\n",
      "                'run': {'max_episodes': 1000000,\n",
      "                        'max_steps': 1000000,\n",
      "                        'max_steps_per_episode': 100000,\n",
      "                        'max_time': 14400}},\n",
      " 'LunarLander': {'env': {'env_config': {},\n",
      "                         'env_name': 'LunarLander-v3',\n",
      "                         'seed': 43},\n",
      "                 'run': {'max_episodes': 100000,\n",
      "                         'max_steps': 200000,\n",
      "                         'max_steps_per_episode': 100000,\n",
      "                         'max_time': 7200}},\n",
      " 'MountainCar': {'env': {'env_config': {},\n",
      "                         'env_name': 'MountainCar-v0',\n",
      "                         'seed': 43},\n",
      "                 'run': {'max_episodes': 100000,\n",
      "                         'max_steps': 300000,\n",
      "                         'max_steps_per_episode': 100000,\n",
      "                         'max_time': 9000.0}},\n",
      " 'SeaQuest': {'env': {'env_config': {},\n",
      "                      'env_name': 'Seaquest-ramNoFrameskip-v4',\n",
      "                      'seed': 43},\n",
      "              'run': {'max_episodes': 1000000,\n",
      "                      'max_steps': 2000000,\n",
      "                      'max_steps_per_episode': 1000000,\n",
      "                      'max_time': 28800}}}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS BLOCK\n",
    "# IF YOU CHANGE ANYTHING ABOUT ENVIRONMENTS AND THEIR RUN CONFIGS, YOUR CODE WILL NOT BE GRADED\n",
    "from pprint import pprint\n",
    "ENVS = envs()\n",
    "pprint(ENVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0dcf368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:39.400868Z",
     "iopub.status.busy": "2025-06-13T15:46:39.400662Z",
     "iopub.status.idle": "2025-06-13T15:46:39.536298Z",
     "shell.execute_reply": "2025-06-13T15:46:39.535413Z"
    },
    "papermill": {
     "duration": 0.167803,
     "end_time": "2025-06-13T15:46:39.537600",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.369797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your machine is detected as Kaggle\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    set_wandb_key_form_secrets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef112e",
   "metadata": {
    "papermill": {
     "duration": 0.029051,
     "end_time": "2025-06-13T15:46:39.598022",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.568971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 💻 Algorithms Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2c7d7",
   "metadata": {
    "papermill": {
     "duration": 0.030161,
     "end_time": "2025-06-13T15:46:39.658433",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.628272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Epsilon Greedy DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3fb0c",
   "metadata": {
    "papermill": {
     "duration": 0.029284,
     "end_time": "2025-06-13T15:46:39.718349",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.689065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Consider the following implementation as a reference for implementing other algorithms.\n",
    "\n",
    "You can also use it as a baseline for comparing the performance of subsequent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e7ee24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:39.779749Z",
     "iopub.status.busy": "2025-06-13T15:46:39.779478Z",
     "iopub.status.idle": "2025-06-13T15:46:39.791086Z",
     "shell.execute_reply": "2025-06-13T15:46:39.790538Z"
    },
    "papermill": {
     "duration": 0.043424,
     "end_time": "2025-06-13T15:46:39.792130",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.748706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpsGreedyDQNAgent(BaseDQNAgent):\n",
    "    \"\"\"\n",
    "    Epsilon-greedy DQN agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon: float = 0.1, eps_decay: float = 0.999, eps_min: float = 0.01, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_decay = eps_decay\n",
    "        self.eps_min = eps_min\n",
    "\n",
    "    def _decay_eps(self):\n",
    "        \"\"\"\n",
    "        Decay the epsilon value.\n",
    "        \"\"\"\n",
    "        self.epsilon = max(self.epsilon * self.eps_decay, self.eps_min)\n",
    "\n",
    "    def _create_replay_buffer(self, max_size=1000000):\n",
    "        self.replay_buffer = ReplayBuffer(\n",
    "            [\n",
    "                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n",
    "                (\"action\", (), torch.int64),\n",
    "                (\"reward\", (), torch.float32),\n",
    "                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n",
    "                (\"done\", (), torch.float32),\n",
    "            ],\n",
    "            max_size=max_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "    def _create_network(self):\n",
    "        self.q_network = nn.Sequential(\n",
    "            nn.Linear(self.env.observation_space.shape[0], 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.env.action_space.n),\n",
    "        ).to(self.device)\n",
    "        self.q_network.apply(\n",
    "            lambda m: torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
    "            if isinstance(m, nn.Linear)\n",
    "            else None\n",
    "        )\n",
    "        self.target_network = nn.Sequential(\n",
    "            nn.Linear(self.env.observation_space.shape[0], 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.env.action_space.n),\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _compute_loss(self, batch):\n",
    "        \"\"\"\n",
    "        Compute the loss for the DQN agent.\n",
    "        \"\"\"\n",
    "        states = batch[\"state\"]\n",
    "        actions = batch[\"action\"]\n",
    "        rewards = batch[\"reward\"]\n",
    "        next_states = batch[\"next_state\"]\n",
    "        dones = batch[\"done\"]\n",
    "\n",
    "        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        next_q_values = self.target_network(next_states).max(1)[0]\n",
    "        expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        loss = nn.SmoothL1Loss()(q_values, expected_q_values)\n",
    "        return loss\n",
    "\n",
    "    def _act_in_training(self, state):\n",
    "        \"\"\"\n",
    "        Select an action during training.\n",
    "        \"\"\"\n",
    "        self._decay_eps()\n",
    "        if torch.rand(1).item() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network(torch.as_tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n",
    "                return q_values.argmax().item()\n",
    "\n",
    "    def _act_in_eval(self, state):\n",
    "        \"\"\"\n",
    "        Select an action during evaluation.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            q_values = self.q_network(torch.as_tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "    def _wandb_train_step_dict(self):\n",
    "        log_dict = super()._wandb_train_step_dict()\n",
    "        log_dict[\"train_step/epsilon\"] = self.epsilon\n",
    "        return log_dict\n",
    "\n",
    "    def _save_dict(self):\n",
    "        save_dict = super()._save_dict()\n",
    "        save_dict[\"epsilon\"] = self.epsilon\n",
    "        save_dict[\"eps_decay\"] = self.eps_decay\n",
    "        save_dict[\"eps_min\"] = self.eps_min\n",
    "        return save_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70906b86",
   "metadata": {
    "papermill": {
     "duration": 0.029584,
     "end_time": "2025-06-13T15:46:39.852482",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.822898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bootstrap DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec4ff2",
   "metadata": {
    "papermill": {
     "duration": 0.029999,
     "end_time": "2025-06-13T15:46:39.912906",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.882907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Paper: [Deep Exploration via Bootstrapped DQN](https://arxiv.org/abs/1602.04621)\n",
    "\n",
    "**40 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc0d1a",
   "metadata": {
    "papermill": {
     "duration": 0.031018,
     "end_time": "2025-06-13T15:46:39.974324",
     "exception": false,
     "start_time": "2025-06-13T15:46:39.943306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Details\n",
    "\n",
    "In this algorithm, instead of using a single network, we maintain an ensemble of networks (or a single network with multiple heads). At the start of each training episode, we randomly select one of these networks (heads) and use it to choose actions for the entire episode. This strategy approximates Thompson Sampling for the K-armed Bandit problem, enabling deeper exploration by leveraging the diversity among the ensemble members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909c868",
   "metadata": {
    "papermill": {
     "duration": 0.029704,
     "end_time": "2025-06-13T15:46:40.033349",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.003645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c4e327a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:40.094897Z",
     "iopub.status.busy": "2025-06-13T15:46:40.094362Z",
     "iopub.status.idle": "2025-06-13T15:46:40.234756Z",
     "shell.execute_reply": "2025-06-13T15:46:40.234066Z"
    },
    "papermill": {
     "duration": 0.172956,
     "end_time": "2025-06-13T15:46:40.236139",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.063183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadQNet(nn.Module):\n",
    "    def __init__(self, observation_space_dim, network_hidden_dim, action_space_size, count_heads):\n",
    "        super().__init__()\n",
    "        self.count_heads = count_heads\n",
    "        \n",
    "        self.feature_extractor_layers = nn.Sequential(\n",
    "            nn.Linear(observation_space_dim, network_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(network_hidden_dim, network_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.q_value_output_layers = nn.ModuleList()\n",
    "        for _ in range(self.count_heads):\n",
    "            self.q_value_output_layers.append(nn.Linear(network_hidden_dim, action_space_size))\n",
    "        \n",
    "        self._setup_initial_weights()\n",
    "    \n",
    "    def _setup_initial_weights(self):\n",
    "        for layer_module in self.feature_extractor_layers:\n",
    "            if isinstance(layer_module, nn.Linear):\n",
    "                torch.nn.init.orthogonal_(layer_module.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
    "        \n",
    "        for q_head_module in self.q_value_output_layers:\n",
    "            torch.nn.init.orthogonal_(q_head_module.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n",
    "    \n",
    "    def forward(self, input_data, head_index=None):\n",
    "        shared_representations = self.feature_extractor_layers(input_data)\n",
    "        \n",
    "        if head_index is not None:\n",
    "            return self.q_value_output_layers[head_index](shared_representations)\n",
    "        \n",
    "        all_head_outputs = []\n",
    "        for current_head in self.q_value_output_layers:\n",
    "            all_head_outputs.append(current_head(shared_representations))\n",
    "        return torch.stack(all_head_outputs, dim=1)\n",
    "\n",
    "class BootstrapDQNAgent(EpsGreedyDQNAgent):\n",
    "    \"\"\"\n",
    "    Bootstrap DQN agent.\n",
    "    \"\"\"\n",
    "\n",
    "    # Recommended methods to implement/override:\n",
    "\n",
    "    def __init__(self, k: int = 10, bernoulli_p: float = 0.5, **kwargs):\n",
    "        self.k = k\n",
    "        super().__init__(**kwargs)\n",
    "        self.bernoulli_p = bernoulli_p\n",
    "        # you may initialize the Bernoulli distribution\n",
    "        self._bernoulli = Bernoulli(torch.tensor(self.bernoulli_p))\n",
    "        # you may initialize the current head\n",
    "        self.current_head = 0\n",
    "\n",
    "    def _create_network(self):\n",
    "        # build multi-head q and target nets\n",
    "        self.q_network = MultiHeadQNet(\n",
    "            self.env.observation_space.shape[0], 256, self.env.action_space.n, self.k\n",
    "        ).to(self.device)\n",
    "        self.target_network = MultiHeadQNet(\n",
    "            self.env.observation_space.shape[0], 256, self.env.action_space.n, self.k\n",
    "        ).to(self.device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def _create_replay_buffer(self, max_size=1000000):\n",
    "        # You may want to add masks to the replay buffer\n",
    "        self.replay_buffer = ReplayBuffer([\n",
    "            (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n",
    "            (\"action\", (), torch.int64),\n",
    "            (\"reward\", (), torch.float32),\n",
    "            (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n",
    "            (\"done\", (), torch.float32),\n",
    "            (\"mask\", (self.k,), torch.float32),\n",
    "        ], max_size=max_size, device=self.device)\n",
    "\n",
    "    def _preprocess_add(self, state, action, reward, next_state, done):\n",
    "        # You may generate masks here\n",
    "        states = self._state_transformation(state)\n",
    "        next_states = self._state_transformation(next_state)\n",
    "        \n",
    "        actions = torch.tensor(action, dtype=torch.int64, device=self.device)\n",
    "        rewards = torch.tensor(reward, dtype=torch.float32, device=self.device)\n",
    "        dones = torch.tensor(done, dtype=torch.float32, device=self.device)\n",
    "        masks = self._bernoulli.sample((self.k,)).float().to(self.device)\n",
    "        return {\n",
    "            \"state\": states,\n",
    "            \"action\": actions,\n",
    "            \"reward\": rewards,\n",
    "            \"next_state\": next_states,\n",
    "            \"done\": dones,\n",
    "            \"mask\": masks,\n",
    "        }\n",
    "\n",
    "    def _compute_loss(self, batch):\n",
    "        # compute mask-weighted bootstrap TD loss\n",
    "        states, actions, rewards, next_states, dones, masks = (\n",
    "            batch[\"state\"],\n",
    "            batch[\"action\"],\n",
    "            batch[\"reward\"],\n",
    "            batch[\"next_state\"],\n",
    "            batch[\"done\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        all_q = self.q_network(states)\n",
    "        with torch.no_grad():\n",
    "            all_next_q = self.target_network(next_states)\n",
    "            max_next_q = all_next_q.max(dim=2)[0]\n",
    "        loss_list = []\n",
    "        for head_idx in range(self.k):\n",
    "            q_vals = all_q[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "            td_target = rewards + (1 - dones) * self.gamma * max_next_q[:, head_idx]\n",
    "            head_mask = masks[:, head_idx]\n",
    "            if head_mask.sum() > 0:\n",
    "                loss_val = F.smooth_l1_loss(\n",
    "                    q_vals * head_mask, td_target * head_mask, reduction=\"sum\"\n",
    "                )\n",
    "                loss_list.append(loss_val / head_mask.sum())\n",
    "        return torch.stack(loss_list).mean()\n",
    "\n",
    "    def _episode(self):\n",
    "        super()._episode()\n",
    "        # You may want to sample the current head here\n",
    "        self.current_head = random.randrange(self.k)\n",
    "\n",
    "    def _act_in_training(self, state):\n",
    "        self._decay_eps()\n",
    "        # epsilon greedy for chosen head\n",
    "        if torch.rand(1).item() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        input_tensor = torch.as_tensor(\n",
    "            state, dtype=torch.float32, device=self.device\n",
    "        ).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.q_network(input_tensor, head_index=self.current_head)\n",
    "        return q_values.argmax().item()\n",
    "\n",
    "    def _act_in_eval(self, state):\n",
    "        # average over heads at eval\n",
    "        input_tensor = torch.as_tensor(\n",
    "            state, dtype=torch.float32, device=self.device\n",
    "        ).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_mean = self.q_network(input_tensor).mean(dim=1)\n",
    "        return q_mean.squeeze().argmax().item()\n",
    "\n",
    "    def _wandb_train_episode_dict(self):\n",
    "        log_dict = super()._wandb_train_episode_dict()\n",
    "        # you may want to add some additional information to the log_dict\n",
    "        log_dict[\"train_episode/current_head\"] = self.current_head\n",
    "        return log_dict\n",
    "\n",
    "    def _save_dict(self):\n",
    "        save_dict = super()._save_dict()\n",
    "        save_dict[\"k\"] = self.k\n",
    "        save_dict[\"bernoulli_p\"] = self.bernoulli_p\n",
    "        # you may want to add some additional information to the save_dict\n",
    "        save_dict[\"current_head\"] = self.current_head\n",
    "        return save_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66791e",
   "metadata": {
    "papermill": {
     "duration": 0.029868,
     "end_time": "2025-06-13T15:46:40.297646",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.267778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bootstrap DQN with Randomized Prior Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a63ad",
   "metadata": {
    "papermill": {
     "duration": 0.032007,
     "end_time": "2025-06-13T15:46:40.359577",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.327570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Paper: [Randomized Prior Functions for Deep Reinforcement Learning](https://arxiv.org/abs/1806.03335)\n",
    "\n",
    "**25 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb37b49",
   "metadata": {
    "papermill": {
     "duration": 0.030806,
     "end_time": "2025-06-13T15:46:40.421286",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.390480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450001e6",
   "metadata": {
    "papermill": {
     "duration": 0.029495,
     "end_time": "2025-06-13T15:46:40.483023",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.453528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This method is very similar to Bootstrap DQN, but introduces additional **non-trainable** networks (with multiple heads) called random priors. These priors are added to the Q-network outputs to encourage diversity among ensemble members, both across states and over time. During training, the Q-networks learn to compensate for the effect of these fixed random priors, which helps maintain exploration.\n",
    "\n",
    "##### Notes\n",
    "- Random prior networks are typically smaller (narrower and shallower) than the main Q-networks, so the Q-networks tend to distill their influence during training.\n",
    "- There is a $\\delta_\\mathrm{RPF}$ coefficient to control the strength of the random priors, but for simplicity, you can set $\\delta_\\mathrm{RPF}=1$ and omit tuning this hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8902a",
   "metadata": {
    "papermill": {
     "duration": 0.030055,
     "end_time": "2025-06-13T15:46:40.542864",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.512809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9af05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:40.606152Z",
     "iopub.status.busy": "2025-06-13T15:46:40.605852Z",
     "iopub.status.idle": "2025-06-13T15:46:40.620865Z",
     "shell.execute_reply": "2025-06-13T15:46:40.620171Z"
    },
    "papermill": {
     "duration": 0.048437,
     "end_time": "2025-06-13T15:46:40.622085",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.573648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PriorMultiHeadQNet(MultiHeadQNet): # inheriting from MultiHeadQNet is optional\n",
    "    # you may want to create shallower neural net for the prior network\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_heads):\n",
    "        super().__init__(input_dim,hidden_dim,output_dim,num_heads)\n",
    "        self.shared_layer = torch.nn.Linear(input_dim,hidden_dim//2)\n",
    "        self.prior_heads = torch.nn.ModuleList([torch.nn.Linear(hidden_dim//2,output_dim) for _ in range(num_heads)])\n",
    "        self._init_weights()\n",
    "        self._freeze_parameters()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            torch.nn.init.orthogonal_(self.shared_layer.weight,gain=0.5)\n",
    "            torch.nn.init.zeros_(self.shared_layer.bias)\n",
    "            for layer in self.prior_heads:\n",
    "                torch.nn.init.orthogonal_(layer.weight,gain=0.5)\n",
    "                torch.nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def _freeze_parameters(self):\n",
    "        for p in self.parameters(): p.requires_grad=False\n",
    "\n",
    "    def forward(self,x,head_idx=None):\n",
    "        features=F.relu(self.shared_layer(x))\n",
    "        if head_idx is not None:\n",
    "            return self.prior_heads[head_idx](features)\n",
    "        out_list=[]\n",
    "        for h in self.prior_heads:\n",
    "          out_list.append(h(features))\n",
    "        return torch.stack(out_list,dim=1)\n",
    "\n",
    "class RPFBootstrapDQNAgent(BootstrapDQNAgent):\n",
    "\n",
    "    # Recommended methods to implement/override:\n",
    "\n",
    "    def _create_network(self):\n",
    "        super()._create_network()\n",
    "        # you may want to create the prior network here\n",
    "        self.prior_network=PriorMultiHeadQNet(self.env.observation_space.shape[0],256,self.env.action_space.n,self.k).to(self.device)\n",
    "        self.target_prior_network=PriorMultiHeadQNet(self.env.observation_space.shape[0],256,self.env.action_space.n,self.k).to(self.device)\n",
    "        self.target_prior_network.load_state_dict(self.prior_network.state_dict())\n",
    "\n",
    "    def _act_in_training(self,state):\n",
    "        self._decay_eps()\n",
    "        if torch.rand(1).item()<self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_vals=self.q_network(s,head_index=self.current_head)\n",
    "            p_vals=self.prior_network(s,head_idx=self.current_head)\n",
    "            augmented_vals = q_vals+p_vals\n",
    "        return augmented_vals.argmax().item()\n",
    "\n",
    "    def _act_in_eval(self,state):\n",
    "        # you may average q+prior across heads\n",
    "        s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_all=self.q_network(s)\n",
    "            p_all=self.prior_network(s)\n",
    "            combo_all=q_all+p_all\n",
    "            avg_combo=combo_all.mean(dim=1)\n",
    "        return avg_combo.squeeze().argmax().item()\n",
    "\n",
    "    def _compute_loss(self,batch):\n",
    "        states,actions,rewards,next_states,dones,masks=(batch[\"state\"],batch[\"action\"],batch[\"reward\"],batch[\"next_state\"],batch[\"done\"],batch[\"mask\"])\n",
    "        q_all=self.q_network(states)\n",
    "        p_all=self.prior_network(states)\n",
    "        augmented_vals=q_all+p_all\n",
    "        with torch.no_grad():\n",
    "            q_next=self.target_network(next_states)\n",
    "            p_next=self.target_prior_network(next_states)\n",
    "            aug_next=q_next+p_next\n",
    "            max_next=aug_next.max(dim=2)[0]\n",
    "        losses=[]\n",
    "        for h in range(self.k):\n",
    "            qh=augmented_vals[:,h,:].gather(1,actions.unsqueeze(1)).squeeze(1)\n",
    "            target=rewards+(1-dones)*self.gamma*max_next[:,h]\n",
    "            mh=masks[:,h]\n",
    "            if mh.sum()>0:\n",
    "                l=F.smooth_l1_loss(qh*mh,target*mh,reduction=\"sum\")/mh.sum()\n",
    "                losses.append(l)\n",
    "        return torch.stack(losses).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4b28e",
   "metadata": {
    "papermill": {
     "duration": 0.034104,
     "end_time": "2025-06-13T15:46:40.690804",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.656700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003bc97",
   "metadata": {
    "papermill": {
     "duration": 0.033246,
     "end_time": "2025-06-13T15:46:40.757316",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.724070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Paper: [Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation](https://arxiv.org/abs/2201.01666)\n",
    "\n",
    "**35 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795fcada",
   "metadata": {
    "papermill": {
     "duration": 0.033726,
     "end_time": "2025-06-13T15:46:40.823755",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.790029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce7e66",
   "metadata": {
    "papermill": {
     "duration": 0.035354,
     "end_time": "2025-06-13T15:46:40.894741",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.859387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This method does not explicitly address the exploration problem but focuses on improving sample efficiency.\n",
    "\n",
    "By maintaining an ensemble of Q-networks, multiple Q-values can be computed for each state-action pair. This enables the estimation of uncertainty in the target values. Using this uncertainty, a weighted loss is calculated, where the weights are inversely proportional to the uncertainty. The more confident we are about a target, the higher its weight during the update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d782293",
   "metadata": {
    "papermill": {
     "duration": 0.035963,
     "end_time": "2025-06-13T15:46:40.965708",
     "exception": false,
     "start_time": "2025-06-13T15:46:40.929745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logging Effective Batch Size (EBS) helps you to tune $\\xi$ parameter:\n",
    "\n",
    "$$\n",
    "EBS = \\dfrac{\\left(\\sum^K_k w_k\\right)^2}{\\sum_k^K w_k^2} = \\dfrac{\\left(\\sum_k^K \\dfrac{1}{(\\sigma_k^2 + \\xi)}\\right)^2}{\\sum_k^K\\dfrac{1}{(\\sigma_k^2 + \\xi)^2}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33401372",
   "metadata": {
    "papermill": {
     "duration": 0.035285,
     "end_time": "2025-06-13T15:46:41.036702",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.001417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e744ee2",
   "metadata": {
    "papermill": {
     "duration": 0.037055,
     "end_time": "2025-06-13T15:46:41.108850",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.071795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Use the minimum Effective Batch Size (EBS) as a hyperparameter instead of $\\xi$, and numerically calculate $\\xi$ during each training step based on the minimum EBS. (5 points)\n",
    "2. Implement the complete IV-DQN algorithm as described in the appendix of the original paper. (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9950b",
   "metadata": {
    "papermill": {
     "duration": 0.034617,
     "end_time": "2025-06-13T15:46:41.179522",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.144905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d7b19bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.252099Z",
     "iopub.status.busy": "2025-06-13T15:46:41.251783Z",
     "iopub.status.idle": "2025-06-13T15:46:41.268279Z",
     "shell.execute_reply": "2025-06-13T15:46:41.267553Z"
    },
    "papermill": {
     "duration": 0.054373,
     "end_time": "2025-06-13T15:46:41.269526",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.215153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n",
    "\n",
    "    # Recommended methods to implement/override:\n",
    "\n",
    "    def __init__(self, xi: float = 0.5, min_ebs: float = 8.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.xi = xi\n",
    "        self.last_uncert_weights = None\n",
    "        self.last_ebs = None\n",
    "        self.last_mean_var = None\n",
    "        self.xi_lr = 0.01\n",
    "        self.xi_min = 1e-6\n",
    "        self.xi_max = 100.0\n",
    "        self.min_effective_batch_size = min_ebs\n",
    "\n",
    "    def _compute_loss(self, batch):\n",
    "        states, actions, rewards, next_states, dones, masks = (\n",
    "            batch[\"state\"], batch[\"action\"], batch[\"reward\"],\n",
    "            batch[\"next_state\"], batch[\"done\"], batch[\"mask\"]\n",
    "        )\n",
    "        bs = states.shape[0]\n",
    "        q_all = self.q_network(states)\n",
    "        prior_all = self.prior_network(states)\n",
    "        combined = q_all + prior_all\n",
    "        act_idx = actions.unsqueeze(1).unsqueeze(2).expand(-1, self.k, -1)\n",
    "        q_sel = combined.gather(2, act_idx).squeeze(2)\n",
    "        with torch.no_grad():\n",
    "            next_q = self.target_network(next_states)\n",
    "            next_prior = self.target_prior_network(next_states)\n",
    "            next_comb = next_q + next_prior\n",
    "            main_nq = (self.q_network(next_states) + self.prior_network(next_states)).mean(dim=1).argmax(dim=1)\n",
    "            na = main_nq.unsqueeze(1).unsqueeze(2).expand(-1, self.k, -1)\n",
    "            nvals = next_comb.gather(2, na).squeeze(2)\n",
    "            target = rewards.unsqueeze(-1) + (1-dones.unsqueeze(-1))*self.gamma*nvals\n",
    "        var = target.var(dim=1, keepdim=True)\n",
    "        # dynamic xi update\n",
    "        w = bs/(var + self.xi)\n",
    "        w = w*bs/w.sum()\n",
    "        # compute effective batch size\n",
    "        w_flat = w.reshape(-1); sw=w_flat.sum(); sw2=(w_flat**2).sum()\n",
    "        ebs = (sw**2/sw2).item() if sw2>0 else 0.0\n",
    "        if ebs < self.min_effective_batch_size:\n",
    "            lo, hi, tgt = self.xi_min, self.xi_max, self.min_effective_batch_size\n",
    "            for _ in range(20):\n",
    "                mid = (lo+hi)/2\n",
    "                tw = bs/(var+mid); tw=tw*bs/tw.sum()\n",
    "                wf=tw.reshape(-1); swf=wf.sum(); sw2f=(wf**2).sum()\n",
    "                tebs = (swf**2/sw2f).item() if sw2f>0 else 0.0\n",
    "                if abs(tebs-tgt)<0.1: break\n",
    "                hi=mid if tebs<tgt else hi; lo=mid if tebs>tgt else lo\n",
    "            new_xi = mid\n",
    "        else:\n",
    "            new_xi = self.xi\n",
    "        self.xi = float(torch.clamp(torch.tensor(self.xi*(1-self.xi_lr)+new_xi*self.xi_lr),\n",
    "                                    self.xi_min, self.xi_max))\n",
    "        self.last_ebs = ebs\n",
    "        self.last_mean_var = var.mean().item()\n",
    "        # recompute weights with updated xi\n",
    "        uw = 1.0/(var+self.xi); uw=uw*bs/uw.sum(); uw=uw.expand(-1,self.k)\n",
    "        self.last_uncert_weights = uw.detach()\n",
    "        losses = []\n",
    "        for h in range(self.k):\n",
    "            pred = q_sel[:,h]; tgt = target[:,h]; mw = uw[:,h]\n",
    "            l = F.smooth_l1_loss(pred, tgt, reduction=\"none\")\n",
    "            losses.append((l*mw).mean())\n",
    "        return sum(losses)/len(losses) if losses else torch.tensor(0.0, device=self.device)\n",
    "\n",
    "    def _save_dict(self):\n",
    "        save = super()._save_dict()\n",
    "        save[\"xi\"] = self.xi\n",
    "        save[\"xi_lr\"] = self.xi_lr\n",
    "        save[\"xi_min\"] = self.xi_min\n",
    "        save[\"xi_max\"] = self.xi_max\n",
    "        return save\n",
    "\n",
    "    def _wandb_train_step_dict(self):\n",
    "        log = super()._wandb_train_step_dict()\n",
    "        # you may want to add some additional information to the log_dict\n",
    "        log[\"train/computed_xi\"] = self.xi\n",
    "        if self.last_ebs is not None:\n",
    "            log[\"train/ebs\"] = self.last_ebs\n",
    "            log[\"train/ebs_ratio\"] = self.last_ebs/self.min_effective_batch_size\n",
    "        if self.last_mean_var is not None:\n",
    "            log[\"train/mean_uncertainty\"] = self.last_mean_var\n",
    "        if self.last_uncert_weights is not None:\n",
    "            w = self.last_uncert_weights\n",
    "            log[\"train/uw_mean\"] = w.mean().item()\n",
    "            log[\"train/uw_std\"] = w.std().item()\n",
    "        return log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7e51",
   "metadata": {
    "papermill": {
     "duration": 0.035,
     "end_time": "2025-06-13T15:46:41.339690",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.304690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### IV-DQN\n",
    "Implemented it with the UCB exploration strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fce89ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.412665Z",
     "iopub.status.busy": "2025-06-13T15:46:41.412196Z",
     "iopub.status.idle": "2025-06-13T15:46:41.436768Z",
     "shell.execute_reply": "2025-06-13T15:46:41.435844Z"
    },
    "papermill": {
     "duration": 0.063124,
     "end_time": "2025-06-13T15:46:41.438153",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.375029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IVQNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.q_head = nn.Linear(hidden_dim, output_dim)\n",
    "        self.info_head = nn.Linear(hidden_dim, output_dim)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.shared_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "        nn.init.orthogonal_(self.q_head.weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "        nn.init.orthogonal_(self.info_head.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.shared_layers(x)\n",
    "        q_vals = self.q_head(feats)\n",
    "        info_vals = self.info_head(feats)\n",
    "        return q_vals, info_vals\n",
    "\n",
    "class IVDQNAgent(EpsGreedyDQNAgent):\n",
    "    def __init__(\n",
    "        self, beta: float = 1.0, info_lr: float = 1e-4, max_errors: int = 1000,\n",
    "        info_update_freq: int = 1, **kwargs\n",
    "    ):\n",
    "        self.info_lr = info_lr\n",
    "        self.beta = beta\n",
    "        self.info_update_freq = info_update_freq\n",
    "        super().__init__(**kwargs)\n",
    "        self._info_step = 0\n",
    "        self.error_history = []\n",
    "        self.max_errors = max_errors\n",
    "\n",
    "    def _create_network(self):\n",
    "        self.q_network = IVQNet(\n",
    "            input_dim=self.env.observation_space.shape[0],\n",
    "            hidden_dim=256,\n",
    "            output_dim=self.env.action_space.n\n",
    "        ).to(self.device)\n",
    "        self.target_network = IVQNet(\n",
    "            input_dim=self.env.observation_space.shape[0],\n",
    "            hidden_dim=256,\n",
    "            output_dim=self.env.action_space.n\n",
    "        ).to(self.device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.target_network.eval()\n",
    "\n",
    "    def _create_optimizer(self):\n",
    "        q_params = list(self.q_network.shared_layers.parameters()) + list(self.q_network.q_head.parameters())\n",
    "        info_params = list(self.q_network.shared_layers.parameters()) + list(self.q_network.info_head.parameters())\n",
    "        self.optimizer = torch.optim.Adam(q_params, lr=self.learning_rate)\n",
    "        self.info_optimizer = torch.optim.Adam(info_params, lr=self.info_lr)\n",
    "\n",
    "    def _compute_loss(self, batch):\n",
    "        S, A, R, NS, D = (\n",
    "            batch[\"state\"], batch[\"action\"], batch[\"reward\"],\n",
    "            batch[\"next_state\"], batch[\"done\"]\n",
    "        )\n",
    "        qv, iv = self.q_network(S)\n",
    "        q_taken = qv.gather(1, A.unsqueeze(1)).squeeze(1)\n",
    "        with torch.no_grad():\n",
    "            nq, _ = self.target_network(NS)\n",
    "            nq_max = nq.max(1)[0]\n",
    "            q_target = R + (1 - D) * self.gamma * nq_max\n",
    "        loss_q = F.smooth_l1_loss(q_taken, q_target)\n",
    "        loss_info = self._compute_info_loss(batch, qv, iv, q_target)\n",
    "        errs = torch.abs(q_taken - q_target)\n",
    "        self.error_history += errs.detach().cpu().tolist()\n",
    "        if len(self.error_history) > self.max_errors:\n",
    "            self.error_history = self.error_history[-self.max_errors:]\n",
    "        return loss_q + loss_info\n",
    "\n",
    "    def _compute_info_loss(self, batch, q_vals, info_vals, q_target):\n",
    "        S, A = batch[\"state\"], batch[\"action\"]\n",
    "        info_taken = info_vals.gather(1, A.unsqueeze(1)).squeeze(1)\n",
    "        q_taken = q_vals.gather(1, A.unsqueeze(1)).squeeze(1)\n",
    "        errs = torch.abs(q_taken - q_target).detach()\n",
    "        return F.mse_loss(info_taken, errs)\n",
    "\n",
    "    def learn(self, batch_size=None):\n",
    "        self._loss = None\n",
    "        if not self.training:\n",
    "            print(\"Agent is not in training mode. It can not learn.\")\n",
    "            return\n",
    "        if batch_size is None:\n",
    "            batch_size = self.default_batch_size\n",
    "        if len(self.replay_buffer) < batch_size or self._training_step < self.start_training_after:\n",
    "            return\n",
    "        batch = self.replay_buffer.sample(batch_size)\n",
    "        if self._norm_rew:\n",
    "            batch[\"reward\"] = self._normalize_reward(batch[\"reward\"])\n",
    "        loss = self._compute_loss(batch)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        if self.gradient_norm_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self._learnable_parameters(), self.gradient_norm_clip)\n",
    "        total_norm = sum(p.grad.data.norm(2).item()**2 for p in self._learnable_parameters() if p.grad is not None)\n",
    "        self.grad_norm = total_norm**0.5\n",
    "        self.optimizer.step()\n",
    "        if self._training_step % self.info_update_freq == 0:\n",
    "            self.info_optimizer.step()\n",
    "            self._info_step += 1\n",
    "        self._soft_update_target_network()\n",
    "        self._loss = loss.item()\n",
    "        self._episode_loss += self._loss\n",
    "        log = self._wandb_train_step_dict()\n",
    "        if self.wandb_run is not None:\n",
    "            self.wandb_run.log(log, step=self._training_step)\n",
    "\n",
    "    def _act_in_training(self, state):\n",
    "        self._decay_eps()\n",
    "        if torch.rand(1).item() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return self._select_action_with_info(state)\n",
    "\n",
    "    def _act_in_eval(self, state):\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            qv, _ = self.q_network(st)\n",
    "            return qv.argmax().item()\n",
    "\n",
    "    def _select_action_with_info(self, state):\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            qv, iv = self.q_network(st)\n",
    "            vals = qv + self.beta * iv\n",
    "            return vals.argmax().item()\n",
    "\n",
    "    def _wandb_train_step_dict(self):\n",
    "        log = super()._wandb_train_step_dict()\n",
    "        log[\"train_step/beta\"] = self.beta\n",
    "        log[\"train_step/info_step\"] = self._info_step\n",
    "        if self.error_history:\n",
    "            log[\"train_step/err_mean\"] = np.mean(self.error_history)\n",
    "            log[\"train_step/err_std\"] = np.std(self.error_history)\n",
    "        return log\n",
    "\n",
    "    def _save_dict(self):\n",
    "        save = super()._save_dict()\n",
    "        save[\"beta\"] = self.beta\n",
    "        save[\"info_lr\"] = self.info_lr\n",
    "        save[\"info_update_freq\"] = self.info_update_freq\n",
    "        save[\"_info_step\"] = self._info_step\n",
    "        return save\n",
    "\n",
    "    def get_info_values(self, state):\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            _, iv = self.q_network(st)\n",
    "            return iv.squeeze().cpu().numpy()\n",
    "\n",
    "    def get_q_and_info_values(self, state):\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            qv, iv = self.q_network(st)\n",
    "            return qv.squeeze().cpu().numpy(), iv.squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb62e5",
   "metadata": {
    "papermill": {
     "duration": 0.035442,
     "end_time": "2025-06-13T15:46:41.508556",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.473114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ⚙️ Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd258606",
   "metadata": {
    "papermill": {
     "duration": 0.036976,
     "end_time": "2025-06-13T15:46:41.581036",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.544060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Feel free to change hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f5446e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.653332Z",
     "iopub.status.busy": "2025-06-13T15:46:41.652545Z",
     "iopub.status.idle": "2025-06-13T15:46:41.658668Z",
     "shell.execute_reply": "2025-06-13T15:46:41.657752Z"
    },
    "papermill": {
     "duration": 0.043771,
     "end_time": "2025-06-13T15:46:41.659968",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.616197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MountainCar is selected.\n"
     ]
    }
   ],
   "source": [
    "env = [\"FrozenLake\", \"CartPole\", \"MountainCar\", \"SeaQuest\", \"LunarLander\"][2]\n",
    "print(f\"{env} is selected.\")\n",
    "\n",
    "base_agent_config = {\n",
    "    **ENVS[env][\"env\"],\n",
    "    \"default_batch_size\": 128,\n",
    "    \"gamma\": 0.99,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"replay_buffer_capacity\":100_000,\n",
    "    \"tau\": 5e-3,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"gradient_norm_clip\": 5.0,\n",
    "    \"start_training_after\": 1000,\n",
    "    \"normalize_rewards\": False,\n",
    "    \"scale_rewards\": None\n",
    "}\n",
    "\n",
    "base_run_config = {\n",
    "    **ENVS[env][\"run\"],\n",
    "    \"learn_every\": 1,  # Apply learning every n steps of rollout\n",
    "    \"eval_every\": 10_000,  # Evaluate model approximately every n steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03266488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.732348Z",
     "iopub.status.busy": "2025-06-13T15:46:41.731481Z",
     "iopub.status.idle": "2025-06-13T15:46:41.735617Z",
     "shell.execute_reply": "2025-06-13T15:46:41.734944Z"
    },
    "papermill": {
     "duration": 0.041678,
     "end_time": "2025-06-13T15:46:41.736935",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.695257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_greedy_config = {\n",
    "    **base_agent_config,\n",
    "    \"eps_decay\": 0.99998,\n",
    "    \"eps_min\": 0.03,\n",
    "    \"epsilon\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95c00213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.809178Z",
     "iopub.status.busy": "2025-06-13T15:46:41.808458Z",
     "iopub.status.idle": "2025-06-13T15:46:41.812342Z",
     "shell.execute_reply": "2025-06-13T15:46:41.811688Z"
    },
    "papermill": {
     "duration": 0.04137,
     "end_time": "2025-06-13T15:46:41.813552",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.772182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_dqn_config = {\n",
    "    **eps_greedy_config,\n",
    "    \"k\": 15,\n",
    "    \"bernoulli_p\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e266e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.886047Z",
     "iopub.status.busy": "2025-06-13T15:46:41.885164Z",
     "iopub.status.idle": "2025-06-13T15:46:41.889095Z",
     "shell.execute_reply": "2025-06-13T15:46:41.888539Z"
    },
    "papermill": {
     "duration": 0.04132,
     "end_time": "2025-06-13T15:46:41.890288",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.848968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rpf_bootstrap_dqn_config = {\n",
    "    **bootstrap_dqn_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9784ed4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:41.962795Z",
     "iopub.status.busy": "2025-06-13T15:46:41.962020Z",
     "iopub.status.idle": "2025-06-13T15:46:41.966214Z",
     "shell.execute_reply": "2025-06-13T15:46:41.965336Z"
    },
    "papermill": {
     "duration": 0.042064,
     "end_time": "2025-06-13T15:46:41.967585",
     "exception": false,
     "start_time": "2025-06-13T15:46:41.925521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ue_bootstrap_dqn_config = {\n",
    "    **rpf_bootstrap_dqn_config,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_ebs\": 8.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25b19490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:42.039275Z",
     "iopub.status.busy": "2025-06-13T15:46:42.038443Z",
     "iopub.status.idle": "2025-06-13T15:46:42.042477Z",
     "shell.execute_reply": "2025-06-13T15:46:42.041824Z"
    },
    "papermill": {
     "duration": 0.041296,
     "end_time": "2025-06-13T15:46:42.043732",
     "exception": false,
     "start_time": "2025-06-13T15:46:42.002436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iv_dqn_config = {\n",
    "    **eps_greedy_config,\n",
    "    \"beta\": 1.0,\n",
    "    \"info_lr\": 4e-4,\n",
    "    \"max_errors\": 1000,\n",
    "    \"info_update_freq\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7d873",
   "metadata": {
    "papermill": {
     "duration": 0.037236,
     "end_time": "2025-06-13T15:46:42.116674",
     "exception": false,
     "start_time": "2025-06-13T15:46:42.079438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🔄 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae48d1",
   "metadata": {
    "papermill": {
     "duration": 0.035074,
     "end_time": "2025-06-13T15:46:42.186533",
     "exception": false,
     "start_time": "2025-06-13T15:46:42.151459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `try-except` block allows you to terminate the current algorithm's run directly from the W&B panel and proceed to the next algorithm without crashing the entire notebook. This can be particularly useful when using Kaggle's *Save Version* feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b924f02",
   "metadata": {
    "papermill": {
     "duration": 0.03429,
     "end_time": "2025-06-13T15:46:42.255696",
     "exception": false,
     "start_time": "2025-06-13T15:46:42.221406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Epsilon Greedy DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5de75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:42.326779Z",
     "iopub.status.busy": "2025-06-13T15:46:42.326046Z",
     "iopub.status.idle": "2025-06-13T15:46:48.506867Z",
     "shell.execute_reply": "2025-06-13T15:46:48.506102Z"
    },
    "papermill": {
     "duration": 6.217787,
     "end_time": "2025-06-13T15:46:48.508315",
     "exception": false,
     "start_time": "2025-06-13T15:46:42.290528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mayeen-pf\u001B[0m (\u001B[33mayeen-pf-sharif-university-of-technology\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.9\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/kaggle/working/wandb/run-20250613_154642-9hyb4bvn\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33meps_greedy\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/9hyb4bvn\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "wandb_config = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"name\": \"eps_greedy\",\n",
    "    \"config\": {**eps_greedy_config, **base_run_config, \"machine\": get_machine()},\n",
    "    \"save_code\": SAVE_CODE,\n",
    "    \"tags\": [\"dqn\", \"eps_greedy\"],\n",
    "}\n",
    "\n",
    "if DEBUG:\n",
    "    wandb_run = None\n",
    "else:\n",
    "    wandb_run = wandb.init(**wandb_config)\n",
    "\n",
    "eps_greedy_dqn_agent = EpsGreedyDQNAgent(wandb_run=wandb_run, **eps_greedy_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad9044d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:46:48.572880Z",
     "iopub.status.busy": "2025-06-13T15:46:48.571961Z",
     "iopub.status.idle": "2025-06-13T16:22:19.290820Z",
     "shell.execute_reply": "2025-06-13T16:22:19.290103Z"
    },
    "papermill": {
     "duration": 2130.750467,
     "end_time": "2025-06-13T16:22:19.292061",
     "exception": false,
     "start_time": "2025-06-13T15:46:48.541594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "error: XDG_RUNTIME_DIR not set in the environment.\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for 300000 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length ▄█████▄▇▅▁▃▅▆▆▃▃▂▂▂▁▆▁▂▁▁▂▃▁▅▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward ▅▁▁▁▁▁▅▂▄█▆▄▃▃▆▆▇▇▇█▃█▇██▇▆█▄▄\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length ██████████▃▆▆█▆▁▃▃█▃▄▄▄▁▂▂▂▁▂▄▅▄▁▄▄▄▄▂▅▄\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▂▅▄▆▆█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return ▁▁▁▁▁▁▁▁▂▂▃▃▄▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇███████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▆▇██\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward ▁▁▁▁▁▁▁▁▁▄▄▄▄▇▇▁▁▁▅▄▄▇█▆▇▇▅▅█▅▅▅▅▅█▅▅▅▅▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return ▁▁▁▁▁▁▂▃▃▃▅▅▅▆▇▇████████████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon █▇▇▆▆▅▅▅▅▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm ▁▁▂▁▁█▃▆▅██▄▆███████████████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▂▄▃▃▃▂█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length 147\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward -147\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length 93\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss 89196.23792\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return -74.16148\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss 8295250.12695\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward -93\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return 83.16176\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon 0.03\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm 5.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss 111675.69531\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33meps_greedy\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/9hyb4bvn\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20250613_154642-9hyb4bvn/logs\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "try:\n",
    "    eps_greedy_dqn_agent.train(**base_run_config)\n",
    "    wandb_run.finish()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f06c6",
   "metadata": {
    "papermill": {
     "duration": 0.030313,
     "end_time": "2025-06-13T16:22:19.354381",
     "exception": false,
     "start_time": "2025-06-13T16:22:19.324068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bootstrap DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0401a23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T16:22:19.415723Z",
     "iopub.status.busy": "2025-06-13T16:22:19.415264Z",
     "iopub.status.idle": "2025-06-13T16:22:20.251290Z",
     "shell.execute_reply": "2025-06-13T16:22:20.250542Z"
    },
    "papermill": {
     "duration": 0.868475,
     "end_time": "2025-06-13T16:22:20.252805",
     "exception": false,
     "start_time": "2025-06-13T16:22:19.384330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.9\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/kaggle/working/wandb/run-20250613_162219-izwyb6bq\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mbootstrap\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/izwyb6bq\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "wandb_config = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"name\": \"bootstrap\",\n",
    "    \"save_code\": SAVE_CODE,\n",
    "    \"tags\": [\"dqn\", \"bootstrap\"],\n",
    "}\n",
    "\n",
    "wandb_config[\"config\"] = {} if TA else {**bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n",
    "\n",
    "if DEBUG:\n",
    "    wandb_run = None\n",
    "else:\n",
    "    wandb_run = wandb.init(**wandb_config)\n",
    "\n",
    "bootstrap_dqn_agent = BootstrapDQNAgent(wandb_run=wandb_run, **bootstrap_dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4618740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T16:22:20.318625Z",
     "iopub.status.busy": "2025-06-13T16:22:20.318390Z",
     "iopub.status.idle": "2025-06-13T17:57:31.107340Z",
     "shell.execute_reply": "2025-06-13T17:57:31.106761Z"
    },
    "papermill": {
     "duration": 5710.822117,
     "end_time": "2025-06-13T17:57:31.108474",
     "exception": false,
     "start_time": "2025-06-13T16:22:20.286357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for 300000 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length ██▃▆▆▁▂█▁▂▇█▃██▄▃▅▂▁▅▃▃▂▁▁▂▂▂▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward ▁▁▆▃▃█▇▁█▇▂▁▆▁▁▅▆▄▇█▄▆▆▇██▇▇▇█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head ▃▁▂▄▂▁▁▂▃▁▄▃▅▇▂▃▄▆▇██▄▁▇▅▇▁▃▃▅▅▄▄▁▇▅▂▆█▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length ██████▄████▇▆▆██▅▅▃▅▃▁▅▃▆▅▂▂▃▃▅▁▃▃▂▁▂▁▅▂\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▅▆█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇█████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▅▄▇█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward ▁▁▁▁▁▁▁▅▁▁▁▁▁▁▄▄▄▇▂▄▇▃▆▆█▄▇▆▄▄▆█▄▇▇▇▇▄█▇\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▅▅▆▆▇▇▇▇▇▇██████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon █▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm ▁▁▁▁▁▂▁▂▂▄▂▁▂▂▂▃▂▂▂▂▃▃▃▃▂███████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▁▁▄▃██\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length 84\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward -84\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head 8\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length 93\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss 6906.14283\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return -75.45125\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss 642271.28357\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward -93\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return 90.55402\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon 0.03\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm 5.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss 2119.94604\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33mbootstrap\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/izwyb6bq\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20250613_162219-izwyb6bq/logs\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "try:\n",
    "    bootstrap_dqn_agent.train(**base_run_config)\n",
    "    wandb_run.finish()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde24f9",
   "metadata": {
    "papermill": {
     "duration": 0.032116,
     "end_time": "2025-06-13T17:57:31.174154",
     "exception": false,
     "start_time": "2025-06-13T17:57:31.142038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bootstrap DQN with Randomized Prior Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f8d13ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:57:31.241204Z",
     "iopub.status.busy": "2025-06-13T17:57:31.240489Z",
     "iopub.status.idle": "2025-06-13T17:57:32.143974Z",
     "shell.execute_reply": "2025-06-13T17:57:32.143199Z"
    },
    "papermill": {
     "duration": 0.938572,
     "end_time": "2025-06-13T17:57:32.145386",
     "exception": false,
     "start_time": "2025-06-13T17:57:31.206814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.9\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/kaggle/working/wandb/run-20250613_175731-om5dgwm2\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mrandomized_prior\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/om5dgwm2\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "wandb_config = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"name\": \"randomized_prior\",\n",
    "    \"save_code\": SAVE_CODE,\n",
    "    \"tags\": [\"dqn\", \"rpf_bootstrap\"],\n",
    "}\n",
    "\n",
    "wandb_config[\"config\"] = {} if TA else {**rpf_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n",
    "\n",
    "if DEBUG:\n",
    "    wandb_run = None\n",
    "else:\n",
    "    wandb_run = wandb.init(**wandb_config)\n",
    "\n",
    "rpf_bootstrap_dqn_agent = RPFBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8963dccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:57:32.216408Z",
     "iopub.status.busy": "2025-06-13T17:57:32.216140Z",
     "iopub.status.idle": "2025-06-13T19:44:19.330148Z",
     "shell.execute_reply": "2025-06-13T19:44:19.329542Z"
    },
    "papermill": {
     "duration": 6407.149934,
     "end_time": "2025-06-13T19:44:19.331457",
     "exception": false,
     "start_time": "2025-06-13T17:57:32.181523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for 300000 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length █▅▂▇▂▂▃▁▄▄▃▄▂▃▄▇▂▁▇▂▃▃▃▇▄▇▁▂▇▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward ▁▄▇▂▇▇▆█▅▅▆▅▇▆▅▂▇█▂▇▆▆▆▂▅▂█▇▂█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head ▇▅▃▇▇▅▅▅▃▇▂▇▇▄▇▃▅▃▂▄▅▃▅▅▂▇▃▇▇▇▁▅▄█▃▇▃▇▄▇\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length ██████▆▇▆█▅▅▅▃▃▅▄▃▅▃▂▄▂▅▅▁▂▂▁▄▄▂▂▂▄▁▄▆▄▄\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▄▄▇▇████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return ▁▁▁▁▁▂▂▂▂▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▃▅▇▇▅█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward ▁▁▁▁▁▄▇▆▇█▇▇▇▄▅▅▅▄▅▇▇▅▇█▅▅▇▅█▇▅▄▃▄▄▄▇▅▄▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return ▁▁▁▁▁▁▁▂▂▂▄▄▅▅▆▆▆▇▇█████████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon ██▇▆▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm ▁▁▂▄▃▅▂▇████████████████████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▁▃▄▅▁▂▂█▇▄\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length 85\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward -85\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head 12\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length 90\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss 200269.80295\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return -72.96584\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss 18024282.26562\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward -90\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return 70.58693\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon 0.03\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm 5.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss 182837.17188\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33mrandomized_prior\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/om5dgwm2\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20250613_175731-om5dgwm2/logs\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "try:\n",
    "    rpf_bootstrap_dqn_agent.train(**base_run_config)\n",
    "    wandb_run.finish()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976649f6",
   "metadata": {
    "papermill": {
     "duration": 0.043887,
     "end_time": "2025-06-13T19:44:19.420885",
     "exception": false,
     "start_time": "2025-06-13T19:44:19.376998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d413ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T19:44:19.510175Z",
     "iopub.status.busy": "2025-06-13T19:44:19.509379Z",
     "iopub.status.idle": "2025-06-13T19:44:20.419200Z",
     "shell.execute_reply": "2025-06-13T19:44:20.418566Z"
    },
    "papermill": {
     "duration": 0.956574,
     "end_time": "2025-06-13T19:44:20.420644",
     "exception": false,
     "start_time": "2025-06-13T19:44:19.464070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.9\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/kaggle/working/wandb/run-20250613_194419-z2qt8f9h\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33muncertainty_estimation\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/z2qt8f9h\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "wandb_config = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"name\": \"uncertainty_estimation\",\n",
    "    \"save_code\": SAVE_CODE,\n",
    "    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n",
    "}\n",
    "\n",
    "wandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n",
    "\n",
    "if DEBUG:\n",
    "    wandb_run = None\n",
    "else:\n",
    "    wandb_run = wandb.init(**wandb_config)\n",
    "\n",
    "ue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **ue_bootstrap_dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4533eba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T19:44:20.508048Z",
     "iopub.status.busy": "2025-06-13T19:44:20.507797Z",
     "iopub.status.idle": "2025-06-13T21:32:44.431107Z",
     "shell.execute_reply": "2025-06-13T21:32:44.430458Z"
    },
    "papermill": {
     "duration": 6503.967101,
     "end_time": "2025-06-13T21:32:44.432391",
     "exception": false,
     "start_time": "2025-06-13T19:44:20.465290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/977882457.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s= torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n",
      "/tmp/ipykernel_19/977882457.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s=torch.tensor(state,dtype=torch.float32,device=self.device).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for 300000 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length ▅▅▄▆██▄▃▅█▅▃▁▃▁▂▁▂▃▂▂▁█▁▂▂▂▂▂▂\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward ▄▄▅▃▁▁▅▆▄▁▄▆█▆█▇█▇▆▇▇█▁█▇▇▇▇▇▇\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:            train/computed_xi ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                    train/ebs ██▇████▇▃▂▁▄▄▅▅▇▇▇▇▇▇▇██▇▇██████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train/ebs_ratio ███████▇▆▆▄▄▄▃▁▄▄▆▇▇▇▇▇▇▇█▇██████▇██████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/mean_uncertainty ▂▁▁▁▁▁▁▁▁▂▃▃▇▇█▆▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                train/uw_mean ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▅▁▁▁▁█▅▁▁▅▁▁▁▅\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                 train/uw_std ▁▁▂▃▄▄▅▆▆▆█▇██▅▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head ▆█▅▅▃▁▃▇▁▄▇▃▇▅▇█▇▄▅▅▃▇▅▂▃▃▇▇▆▅▅▇▃▅▆▅▇▃▂▃\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length ███▆█▇██▇▅▂▃▅▃▃▂▁▁▂▂▂▂▂▃▂▂▂▂▂▂█▃▁▂▂▂▂▂▂▂\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss ▁▄▅▆▆█▇▇▇▆▆▅▄▄▄▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return ▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss ▁▄▄▅▆▆▅█▆▅▄▄▄▄▅▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward ▁▁▁▂▂▁▄▁▆▆█▇█▆▆▇▇▇▇▇▇▇█▇▇▇▇█▇▆▇▇▇▇▇▇▇▇▇▇\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return ▁▁▁▁▁▂▂▂▂▃▃▃▄▄▅▆▆▆▇▇▇▇▇█████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon █▇▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm ▁▂▁▁▂▂▇▅▅▄▃▇▅████████████████▇▇█████▇███\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss ▃▃▃▁▁▁▁▁▂▂▁█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length 108\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward -108\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:            train/computed_xi 0.05\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                    train/ebs 127.89166\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train/ebs_ratio 15.98646\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/mean_uncertainty 0.00117\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                train/uw_mean 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                 train/uw_std 0.02911\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train_episode/current_head 8\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length 108\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss 0.04621\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return -70.88906\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss 4.99083\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward -108\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return 84.04839\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon 0.03\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm 5.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss 0.03436\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33muncertainty_estimation\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/z2qt8f9h\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20250613_194419-z2qt8f9h/logs\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# DON'T CHANGE THIS BLOCK\n",
    "try:\n",
    "    ue_bootstrap_dqn_agent.train(**base_run_config)\n",
    "    wandb_run.finish()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bef04ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:32:44.522078Z",
     "iopub.status.busy": "2025-06-13T21:32:44.521549Z",
     "iopub.status.idle": "2025-06-13T21:32:45.618160Z",
     "shell.execute_reply": "2025-06-13T21:32:45.617494Z"
    },
    "papermill": {
     "duration": 1.143668,
     "end_time": "2025-06-13T21:32:45.619595",
     "exception": false,
     "start_time": "2025-06-13T21:32:44.475927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.9\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/kaggle/working/wandb/run-20250613_213244-jgjxibqi\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33miv_dqn\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/jgjxibqi\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "wandb_config = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"name\": \"iv_dqn\",\n",
    "    \"save_code\": SAVE_CODE,\n",
    "    \"tags\": [\"dqn\", \"iv\"],\n",
    "}\n",
    "\n",
    "wandb_config[\"config\"] = {} if TA else {**iv_dqn_config, **base_run_config, \"machine\": get_machine()}\n",
    "\n",
    "if DEBUG:\n",
    "    wandb_run = None\n",
    "else:\n",
    "    wandb_run = wandb.init(**wandb_config)\n",
    "\n",
    "iv_dqn_agent = IVDQNAgent(wandb_run=wandb_run, **iv_dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af76fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:32:45.715666Z",
     "iopub.status.busy": "2025-06-13T21:32:45.715182Z",
     "iopub.status.idle": "2025-06-13T22:20:05.020267Z",
     "shell.execute_reply": "2025-06-13T22:20:05.019653Z"
    },
    "papermill": {
     "duration": 2839.351378,
     "end_time": "2025-06-13T22:20:05.021643",
     "exception": false,
     "start_time": "2025-06-13T21:32:45.670265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(state, device=self.device),\n",
      "/tmp/ipykernel_19/672711.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
      "/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n",
      "/tmp/ipykernel_19/672711.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  st = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for 300000 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length ▆▆█████▆███▇▆█▅███▃▅▂▂▃▁▁▇▃▅▃▃\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward ▃▃▁▁▁▁▁▃▁▁▁▂▃▁▄▁▁▁▆▄▇▇▆██▂▆▄▆▆\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length ██████████████████████▅▅▂▁▂▂▄▄▄▄▄▁▆▄▆▅▁▂\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▅▇▇▇▇▇███\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▅▅▆▅▅▁█▆▅▅▅▅▅▆▇▇\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▆▇▇▇▇█████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/beta ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon ███▇▆▆▅▅▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          train_step/err_mean ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/err_std ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▄▄▄▆█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm ████▁███████████████████████████████████\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/info_step ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  eval_episode/episode_length 120\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     eval_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      eval_episode/sum_reward -120\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: train_episode/episode_length 59\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      train_episode/mean_loss 226130013.54449\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_return -81.0431\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    train_episode/mean_reward -1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train_episode/sum_loss 13341670799.125\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/sum_reward -59\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     train_episode/var_return 63.0175\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/beta 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/epsilon 0.03\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          train_step/err_mean 3048.84739\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           train_step/err_std 19161.46082\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/grad_norm 5.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         train_step/info_step 299001\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:              train_step/loss 252222048.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run \u001B[33miv_dqn\u001B[0m at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW/runs/jgjxibqi\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at: \u001B[34m\u001B[4mhttps://wandb.ai/ayeen-pf-sharif-university-of-technology/Ayeen-Poostforoushan-DQN-EXPLORE-HW\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20250613_213244-jgjxibqi/logs\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "iv_dqn_agent.train(**base_run_config)\n",
    "wandb_run.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23765.241992,
   "end_time": "2025-06-13T22:20:08.489406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-13T15:44:03.247414",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
